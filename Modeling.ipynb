{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, Lasso\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"QBfantasyDF\", 'rb') as picklefile: \n",
    "    df = pkl.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneccessary columns and put dependent variable column first\n",
    "finalDF = df.drop(['Name', 'Week', 'OPP'], axis=1)\n",
    "col = finalDF.columns\n",
    "col = [col[-2], col[0], col[1], col[2], col[3], col[4], col[5], col[6], col[7], col[8], col[9], col[10], col[12]]\n",
    "finalDF = finalDF[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see correlation numbers\n",
    "finalDF.corr()\n",
    "#sns.pairplot(finalDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for linear regression (test all - Lasso works best)\n",
    "X=finalDF[col[1:]]\n",
    "y=finalDF['Fantasy Points']\n",
    "reg = Lasso()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X_train and X_test data\n",
    "ssX = StandardScaler()\n",
    "X_train_scaled = ssX.fit_transform(X_train)\n",
    "X_test_scaled = ssX.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "scores = cross_val_score(reg, X_train, y_train, cv=10, scoring='r2')\n",
    "model = reg.fit(X_train, y_train)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check coefficients - which can be removed due to overfitting??\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate some features\n",
    "X=finalDF[[col[2], col[3], col[9], col[11]]]\n",
    "y=finalDF['Fantasy Points']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)\n",
    "X_train_scaled = ssX.fit_transform(X_train)\n",
    "X_test_scaled = ssX.transform(X_test)\n",
    "scores = cross_val_score(reg, X_train, y_train, cv=10, scoring='r2')\n",
    "model = reg.fit(X_train, y_train)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mess around with parameters and try to find best fits\n",
    "model = Lasso()\n",
    "parameters = {'alpha': [1e-20, 1e-16, 1e-12], 'fit_intercept': [True,False]}\n",
    "grid = GridSearchCV(model, parameters, cv=10, scoring='r2')\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(grid.cv_results_)\n",
    "print(grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more cross validation\n",
    "best_lasso = grid.best_estimator_\n",
    "best_lasso.fit(X_train_scaled, y_train)\n",
    "scores = cross_val_score(reg, X_train, y_train, cv=10, scoring='r2')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for different alphas in different degrees of complexity\n",
    "score = 0\n",
    "alphas = [1e-15, 1e-12, 1e-9, 1e-6, 1e-3, 1, 1e3, 1e6, 1e9]\n",
    "degrees = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for alpha, degree in zip(alphas, degrees):\n",
    "    est = make_pipeline(PolynomialFeatures(bestDegree), Lasso(alpha=bestAlpha))\n",
    "    est.fit(X_train_scaled, y_train)\n",
    "    current = est.score(X_test_scaled,y_test)\n",
    "    print(current)\n",
    "    if current > score:\n",
    "        score = current\n",
    "        bestAlpha = alpha\n",
    "        bestDegree = degree\n",
    "print(score, bestAlpha, bestDegree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to loop through\n",
    "def getScore(X_train_scaled, X_test_scaled, y_train, y_test):\n",
    "    est = make_pipeline(PolynomialFeatures(2), Lasso(alpha=1e-16))\n",
    "    currentModel = est.fit(X_train_scaled, y_train)\n",
    "    testScore = est.score(X_test_scaled,y_test)\n",
    "    trainScore = est.score(X_train_scaled, y_train)\n",
    "    print(trainScore, testScore)\n",
    "    return (trainScore, testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which columns work the best as features (up to 3 allowed)\n",
    "newHigh = 0\n",
    "for a in range(1,12):\n",
    "    for b in range(1,12):\n",
    "        print(a, b)\n",
    "        for c in range(1,12):\n",
    "            X=finalDF[[col[a], col[b], col[c]]]\n",
    "            y=finalDF['Fantasy Points']\n",
    "            reg = Lasso()\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            X_train_scaled = ssX.fit_transform(X_train)\n",
    "            X_test_scaled = ssX.transform(X_test)\n",
    "            current = getScore(X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "            if current[1] > newHigh and current[1] < 0.99:\n",
    "                newHigh = current[1]\n",
    "                print('NEW HIGH')\n",
    "                print(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing as above, except this time use polynomial features (2)\n",
    "newHigh = 0\n",
    "for a in range(1,12):\n",
    "    print(a)\n",
    "    for b in range(1,12):\n",
    "        print(b)\n",
    "        for c in range(1,12):\n",
    "            X=finalDF[[col[a], col[b], col[c]]]\n",
    "            y=finalDF['Fantasy Points']\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            poly = PolynomialFeatures(2, include_bias=True)\n",
    "            XTrainScaled = poly.fit_transform(X_train)\n",
    "            XTestScaled = poly.transform(X_test)\n",
    "            model = Lasso(alpha=1e-8)\n",
    "            model.fit(XTrainScaled, y_train)\n",
    "            trainR = model.score(XTrainScaled, y_train)\n",
    "            testR = model.score(XTestScaled, y_test)\n",
    "            if testR > newHigh and testR < 0.99:\n",
    "                newHigh = testR\n",
    "                print('NEW HIGH')\n",
    "            print(trainR, testR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best fit is polynomial with complexity of 2 and features 3, 7, and 11, find best alpha\n",
    "X=finalDF[[col[3], col[7], col[11]]]\n",
    "y=finalDF['Fantasy Points']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "poly = PolynomialFeatures(2, include_bias=True)\n",
    "XTrainScaled = poly.fit_transform(X_train)\n",
    "XTestScaled = poly.transform(X_test)\n",
    "myModel = model.fit(XTrainScaled, y_train)\n",
    "trainR = myModel.score(XTrainScaled, y_train)\n",
    "testR = myModel.score(XTestScaled, y_test)\n",
    "print(trainR, testR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph residuals to look for patterns\n",
    "predictions = myModel.predict(XScaled)\n",
    "residuals = predictions - y\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(range(len(residuals)), residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model using all data points\n",
    "XScaled = poly.fit_transform(X)\n",
    "myModel = model.fit(XScaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get final coefficients\n",
    "coeff_dic = {}\n",
    "n = 0\n",
    "for coef_ in myModel.coef_:\n",
    "    if abs(myModel.coef_[n].round(4)) != 0:\n",
    "        coeff_dic[poly.get_feature_names([col[3], col[7], col[11]])[n]] = myModel.coef_[n].round(4)\n",
    "        n+=1\n",
    "    else:\n",
    "        n+=1\n",
    "        \n",
    "print('Ridge Regression Coefficients\\nPolynomial Degree 2\\nAlpha = 1960')\n",
    "print('Intercept:', myModel.intercept_.round(4))\n",
    "print('Total Non-Zero Coefficients: {}\\n'.format(len(coeff_dic)))\n",
    "print(json.dumps(coeff_dic, indent = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
